{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fwpyk7LtzsQ",
    "outputId": "b62fa362-44fb-4a94-e8dc-54324a157e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/209.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m204.8/209.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain pypdf langgraph langchain-community langchain-google-genai langchain-groq faiss-cpu langchain-huggingface langchain-experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cklU-3rbrRex"
   },
   "source": [
    "## Importing Required Liabraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aX5q8FLouCKt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\GenAI\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "# Setting Up API Keys\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBgXK36EMVy1m8mQAEDpo4feTdjUD2hZi0\"\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "# Defining LLM Models\n",
    "llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.4)\n",
    "llm_groq = ChatGroq(temperature=0.9, model_name=\"llama-3.3-70b-specdec\")\n",
    "\n",
    "# Defining Embedding Model\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2',  # Model for text embeddings\n",
    "    model_kwargs={\"device\": \"cuda\"},  # Run on gpu\n",
    "    encode_kwargs={\"normalize_embeddings\": True}  # Normalize embeddings for better accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFVKVfVtr9UE"
   },
   "source": [
    "## Loading & Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Br9DBf4IuORQ"
   },
   "outputs": [],
   "source": [
    "# Loading the document\n",
    "file_path = \"/content/The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bl4YmKbntTjl",
    "outputId": "4741d737-ef5b-4404-9e85-5a014d3c87b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4505/4505 [03:37<00:00, 20.73doc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Splitting completed! Total Chunks: 14026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize Semantic Chunker\n",
    "semantic_splitter = SemanticChunker(hf_embeddings)\n",
    "\n",
    "# Process each document separately and display progress\n",
    "chunks = []\n",
    "for doc in tqdm(documents, desc=\"Splitting Documents\", unit=\"doc\"):\n",
    "    chunks.extend(semantic_splitter.split_documents([doc]))\n",
    "\n",
    "print(f\"âœ… Splitting completed! Total Chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "sNiHdBuZarE0"
   },
   "outputs": [],
   "source": [
    "# Store embeddings in FAISS\n",
    "DB_FAISS_PATH=\"Vectorstore/faiss_db\"\n",
    "vectorstore=FAISS.from_documents(chunks, hf_embeddings)\n",
    "vectorstore.save_local(DB_FAISS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "i8zIlJN0Z6Jf"
   },
   "outputs": [],
   "source": [
    "retrievers = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1RWnZbMw1gD"
   },
   "source": [
    "## Retrieval & Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n2GVYX-nfKlt"
   },
   "outputs": [],
   "source": [
    "# Path where FAISS was saved\n",
    "DB_FAISS_PATH = \"Vectorstore/faiss_db\"\n",
    "\n",
    "# Load the FAISS vectorstore\n",
    "vectorstore = FAISS.load_local(DB_FAISS_PATH, embeddings=hf_embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "1_5YlvY6x2GY"
   },
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# Initialize MultiQueryRetriever to generate multiple query variations\n",
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    llm=llm_gemini,\n",
    "    include_original=True  # Retain the original query alongside reformulated ones\n",
    ")\n",
    "\n",
    "\n",
    "# Define the optimized medical chatbot prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "    You are an **AI-powered medical assistant**, trained to **accurately diagnose and provide concise medical advice**.\n",
    "\n",
    "    **Instructions:**\n",
    "    Based on the userâ€™s query and retrieved medical knowledge, generate a **brief, to-the-point medical response** in the following format:\n",
    "\n",
    "    **ğŸ”¹ Identified Condition:**\n",
    "    - Name of the most relevant disease/condition.\n",
    "\n",
    "    **âš ï¸ Cause:**\n",
    "    - Key reason(s) behind this condition.\n",
    "\n",
    "    **ğŸ¤’ Symptoms:**\n",
    "    - Common and severe symptoms.\n",
    "\n",
    "    **ğŸ’Š Medication & Treatment:**\n",
    "    - Main prescription drugs or OTC treatments.\n",
    "    - Any important home remedies or precautions.\n",
    "\n",
    "    **âœ… Prevention:**\n",
    "    - Simple preventive steps.\n",
    "\n",
    "    **ğŸš¨ When to See a Doctor:**\n",
    "    - **Red flag symptoms** that need **urgent** medical attention.\n",
    "\n",
    "    ---\n",
    "\n",
    "    **ğŸ“– Context (Medical Knowledge Retrieved):**\n",
    "    {context}\n",
    "\n",
    "    **â“ User's Question:**\n",
    "    {question}\n",
    "\n",
    "    **ğŸ“ Response:**\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to format retrieved documents before sending them to the AI model\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([doc.page_content for doc in docs])\n",
    "\n",
    "# Define the pipeline (retrieval + AI model)\n",
    "rag_chain = (\n",
    "    {\"context\": multiquery_retriever | format_docs, \"question\": RunnablePassthrough()}  # Retrieve and format documents\n",
    "    | prompt  # Use the loaded prompt\n",
    "    | llm_gemini  # Generate an answer using the AI model\n",
    "    | StrOutputParser()  # Format the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "j6sypw2qzFu7"
   },
   "outputs": [],
   "source": [
    "question = \"i have pain in my stomach and vomiting, what should i do now\"  # Get user input\n",
    "answer = rag_chain.invoke(question)  # Get the AI's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cm3PsW4Cx2DB",
    "outputId": "07ffa940-a1b7-49a7-af69-e23971bc075d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**ğŸ”¹ Identified Condition:**  Gastroenteritis (or other causes requiring differential diagnosis)\n",
      "\n",
      "**âš ï¸ Cause:**  Viral or bacterial infection, food poisoning, medication side effects, stress, anxiety, or other underlying conditions (e.g., peptic ulcer, gallstones).  Further investigation may be needed to pinpoint the exact cause.\n",
      "\n",
      "**ğŸ¤’ Symptoms:** Stomach pain, vomiting, potentially diarrhea, nausea, dehydration (dry mouth, excessive thirst, scanty urination).  Severe cases may include fever, blood in vomit or stool, and severe abdominal pain.\n",
      "\n",
      "**ğŸ’Š Medication & Treatment:**  Over-the-counter medications like Pepto-Bismol may help relieve symptoms.  For persistent or severe vomiting, antiemetics (e.g., Meclizine, Dimenhydrinate, Ondansetron) may be prescribed.  Sip clear fluids to prevent dehydration.  Introduce bland foods gradually.  Home remedies like ginger or chamomile tea may offer some relief.\n",
      "\n",
      "**âœ… Prevention:**  Practice good hygiene (wash hands frequently), avoid consuming contaminated food or water, manage stress effectively.\n",
      "\n",
      "**ğŸš¨ When to See a Doctor:**  High fever (102Â°F or above), blood in vomit or stool, severe abdominal pain, dehydration, vomiting lasting longer than 48 hours, inability to keep down fluids for 24 hours, suspicion of food poisoning affecting multiple people, or any other concerning symptoms.  Seek immediate medical attention if you suspect a serious underlying condition or experience diabetic shock, severe headache, chest pain, or difficulty breathing.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9myaqg4Z3unF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
